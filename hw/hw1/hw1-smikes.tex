\documentclass[12pt,letterpaper]{hmcpset}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{hyperref}

\input{macros.tex}

% info for header block in upper right hand corner
\name{}
\class{Math189R SU20.1}
\assignment{Homework 1 - Sam Mikes (smikes)}
\duedate{Thursday, June 11, 2020}

\renewcommand{\labelenumi}{{(\alph{enumi})}}


\begin{document}

\begin{problem}[1]
(\textbf{Linear Transformation}) Let $\mathbf{y} = A\mathbf{x} + \mathbf{b}$ be a random vector.
show that expectation is linear:
\[
    \EE[\yy] = \EE[A\xx + \bb] = A\EE[\xx] + \bb.
\]
Also show that
\[
    \cov[\yy] = \cov[A\xx + \bb] = A \cov[\xx] A^\T = A\Sigmab A^\T.
\]
\end{problem}
\begin{solution}

  Expectation for a continuous random variable $x$ with normalized probability distribution function $f_x(x)$ is defined as

\[
  \EE[x]= \int_{-\infty}^{\infty} xf_X(x)dx
\]

  Consider first a single random variable $x$, and $y = ax + b$
\[
\EE[x] = \EE[ax + b]
         = \int_{-\infty}^{\infty} (ax + b) f_X(x) dx
         = a\int_{-\infty}^{\infty} x f_X(x) dx + b \int_{-\infty}^{\infty} f_X(x) dx
         = a\EE[x] + b
\]

In multiple variables, the $x_i$ are independent, so it follows that
\[
   \EE[A\xx + \bb] = A\EE[\xx] + \bb
\]

Covariance is defined
\[
  \CC[\xx] = \EE[(X - \EE[X])(X - \EE[X])^T]
\]

Again, since the expectation $\EE$ is linear in $\xx$, the covariance and any linear transformation of $\xx$ commute and can be rearranged.  The term in $\mathbf{b}$ vanishes because the covariance of a constant term is zero.
\[
  \yy = A\xx + \bb
\]

\[
  \CC(\yy) = \CC(A\xx + \bb)
           = A\CC(x)A^T
\]

Works used: \url{https://www.probabilitycourse.com/chapter6/6_1_5_random_vectors.php}

    \vfill
\end{solution}
\newpage




\begin{problem}[2]
Given the dataset $\Dc = \{(x,y)\} = \{(0,1), (2,3), (3,6), (4,8)\}$
\begin{enumerate}
   \item Find the least squares estimate $y = \thetab^\T\xx$ by hand using
        Cramer's Rule.
    \item Use the normal equations to find the same solution and verify it
        is the same as part (a).
    \item Plot the data and the optimal linear fit you found.
    \item Find randomly generate 100 points near the line with white Gaussian
        noise and then compute the least squares estimate (using a computer).
        Verify that this new line is close to the original and plot the new
        dataset, the old line, and the new line.
\end{enumerate}

\end{problem}
\begin{solution}
1. By Cramer's rule, we have the closed forms
\[
    m = \frac{n\sum_{i=1}^n x_iy_i - (\sum_{i=1}^n x_i)(\sum_{i=1}^n y_i)}{n\sum_{i=1}^n x_i^2 - (\sum_{i=1}^n x_i)^2}
\]
\[
    b = \frac{n\sum_{i=1}^n x_i^2y_i - (\sum_{i=1}^n x_i)(\sum_{i=1}^n x_iy_i)}{n\sum_{i=1}^n x_i^2 - (\sum_{i=1}^n x_i)^2}
\]
Evaluation gives
\[
\sum(x) = 9, \sum(y) = 18, \sum{x^2} = 29, \sum(xy) = 56, \sum(x^2y) = 194
\]
Then
\[
m = \frac{(4*56 - 9*18)}{4*29 - 81}
= \frac{62}{35} =~ 1.77
\]
and
\[
b = \frac{194}{35} =~ 5.54
\]

Numbers, on the other hand, finds $m = b = 1.2$ as the optimal fit.

2. Minimize the error $e$, where

\[
 e = \ee \cdot \ee
\]

\[
 \ee = \yy - ( m \xx + b )
\]

\[
 \ee =
 \begin{bmatrix}
   1 \\
   3 \\
   6 \\
   8 \\
\end{bmatrix}
 - m *
\begin{bmatrix}
  0 \\
  2 \\
  3 \\
  4 \\
\end{bmatrix}
 - b
\]

\[
 \ee =
 \begin{bmatrix}
   1 - b\\
   3 - 2m - b\\
   6 - 3m - b\\
   8 - 4m - b\\
\end{bmatrix}
 \]

\[
e = (1-b)^2 + (3 - 2m - b)^2 + (6 - 3m - b)^2 + (8 - 4m - b)^2
\]

Then find
\[
\begin{aligned}
\frac{\partial e}{\partial m} & = -2m[(3 - 2m - b) + (6 - 3m - b) + (8 - 4m - b)] \\
& = -2(17 - 9m - 3b)
\end{aligned}
\]

\[
\begin{aligned}
\frac{\partial e}{\partial b} & = -2b[(1-b) + (3 - 2m - b) + (6 - 3m - b) + (8 - 4m - b)] \\
& = -2(18 - 9m - 4b)
\end{aligned}
 \]

Used Mathematica to solve this system, with result
\[
  m = \frac{14}{9}, b = 1
\]

 3. Attached graph produced by Numbers.

\includegraphics[scale=0.4]{hw1-p2-graph1.png}

\newpage

4. Using $(m,b) = (1.2, 1.2)$

Generated 100 gaussian random numbers (mean = 0.0, variance = 1.0) from \url{https://www.random.org/gaussian-distributions/?num=100&mean=0.0&stdev=0.5&dec=3&col=1&notation=scientific&format=html&rnd=new}

\includegraphics[scale=0.4]{hw1-p2-graph2.png}

(Data exported in csv format in git repository.)


    \vfill
\end{solution}
\newpage



\end{document}
